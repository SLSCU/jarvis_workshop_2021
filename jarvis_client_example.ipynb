{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jarvis API Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook only shows how to use Jarvis API on ASR and TTS. Find other examples and more details at  https://docs.nvidia.com/deeplearning/jarvis/user-guide/docs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Jarvis API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get Jarvis API Python wheel at https://ngc.nvidia.com/catalog/collections/nvidia:jarvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jarvis_api-1.1.0b0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import librosa\n",
    "import time\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import grpc\n",
    "import requests\n",
    "\n",
    "# ASR proto\n",
    "import jarvis_api.jarvis_asr_pb2 as jasr\n",
    "import jarvis_api.jarvis_asr_pb2_grpc as jasr_srv\n",
    "\n",
    "# TTS proto\n",
    "import jarvis_api.jarvis_tts_pb2 as jtts\n",
    "import jarvis_api.jarvis_tts_pb2_grpc as jtts_srv\n",
    "import jarvis_api.audio_pb2 as ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Jarvis clients and connect to Jarvis Speech API server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = grpc.insecure_channel('localhost:50051')\n",
    "\n",
    "jarvis_asr = jasr_srv.JarvisASRStub(channel)\n",
    "jarvis_tts = jtts_srv.JarvisTTSStub(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio('common_voice_th_23657550_trim.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "with io.open('common_voice_th_23657550_trim.wav', 'rb') as fh:\n",
    "    content = fh.read()\n",
    "req = jasr.RecognizeRequest()\n",
    "req.audio = content                                   # raw bytes\n",
    "req.config.encoding = ja.AudioEncoding.LINEAR_PCM     # Supports LINEAR_PCM, FLAC, MULAW and ALAW audio encodings\n",
    "req.config.sample_rate_hertz = 22050                     # Audio will be resampled if necessary\n",
    "req.config.language_code = \"th-TH\"                    # Ignored, will route to correct model in future release\n",
    "req.config.max_alternatives = 1                       # How many top-N hypotheses to return\n",
    "req.config.enable_automatic_punctuation = False        # Add punctuation when end of VAD detected\n",
    "req.config.audio_channel_count = 1                    # Mono channel\n",
    "\n",
    "response = jarvis_asr.Recognize(req)\n",
    "asr_best_transcript = response.results[0].alternatives[0].transcript\n",
    "\n",
    "print(time.time()-start_time)\n",
    "print(\"ASR Transcript:\", asr_best_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "req = jtts.SynthesizeSpeechRequest()\n",
    "req.text = \"ทดสอบ ระบบ ภาษาไทย\".strip()\n",
    "req.language_code = \"th-TH\"  \n",
    "req.encoding = ja.AudioEncoding.FLAC     # Supports LINEAR_PCM, FLAC, MULAW and ALAW audio encodings\n",
    "req.sample_rate_hz = 22050                     # ignored, audio returned will be 22.05KHz\n",
    "req.voice_name = \"tsync2\"\n",
    "\n",
    "resp = jarvis_tts.Synthesize(req)\n",
    "audio_samples = np.frombuffer(resp.audio, dtype=np.float32)\n",
    "\n",
    "print(time.time()-start_time)\n",
    "\n",
    "ipd.Audio(audio_samples, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
