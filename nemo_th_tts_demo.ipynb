{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeMo Thai TTS Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Tsync2 Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/korakot/corpus/releases/download/v1.0/AIFORTHAI-TSync2Corpus.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip AIFORTHAI-TSync2Corpus.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create menifest for NeMo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeMo menifest format <br>\n",
    "```json\n",
    "{\n",
    "    \"audio_filepath\": \"TSync2_clean/wav/tsync2_noon_48_1058_trim.wav\",\n",
    "    \"text\": \"ปลด แล้ว โปสเตอร์ หวิว เก้า นางเอก\", \n",
    "    \"duration\": 2.507755102040816\n",
    "}\n",
    "{\n",
    "    \"audio_filepath\": \"TSync2_clean/wav/tsync2_noon_50_2872_trim.wav\",\n",
    "    \"text\": \"แต่ หลง ไข่ กรุ๊ป ขอ ต่อรอง ลง เหลือ ราคา สาม ร้อย ถึง สี่ ร้อย ล้าน เหรียญ\", \n",
    "    \"duration\": 5.526349206349207\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.util import normalize, isthaichar\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import wavfile\n",
    "import tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    norm_text = normalize(text)\n",
    "    norm_text = ''.join(char for char in norm_text if isthaichar(char))\n",
    "    words = word_tokenize(norm_text, engine='newmm')\n",
    "    words = [words[i-1] if words[i] == 'ๆ' else words[i] for i in range(len(words))]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def __process(inp):\n",
    "    try:\n",
    "        filepath, out_dir = inp\n",
    "        transcript_path = filepath.replace('/wav/', '/wrd_ph/').replace('.wav', '.txt')\n",
    "        text = open(transcript_path).read().split('\\n')[0].split('|')\n",
    "        text = ' '.join(text)\n",
    "        text = clean_text(text)\n",
    "        \n",
    "\n",
    "        filename = filepath.split('/')[-1]\n",
    "        out_file_path = os.path.join(out_dir, \"wav\", filename.replace('.wav', '_trim.wav'))\n",
    "\n",
    "        y, sr = librosa.load(filepath)\n",
    "        y_trim, _ = librosa.effects.trim(y, top_db=30)\n",
    "        duration = librosa.get_duration(y_trim, sr)\n",
    "\n",
    "        wavfile.write(out_file_path, sr, (y_trim*32768).astype('int16'))\n",
    "        return '{\"audio_filepath\": \"'+out_file_path+'\", \\\n",
    "                           \"text\": \"'+text.strip()+'\", \"duration\": '+str(duration)+'}\\n'\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "def create_menifest(inp_dir, out_dir, num_workers = 30):\n",
    "    file_list = glob.glob(inp_dir+'/wav/*.wav')\n",
    "    \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(os.path.join(out_dir, 'wav'))\n",
    "        \n",
    "    entries = []\n",
    "    with mp.Pool(num_workers) as p:\n",
    "        results = p.imap(__process, [(filepath, out_dir) for filepath in file_list])\n",
    "        for result in tqdm.tqdm(results, total=len(file_list)):\n",
    "            entries.append(result)\n",
    "           \n",
    "    train_files, test_files = train_test_split(entries, test_size=0.05, random_state=42)\n",
    "\n",
    "    print(\"Number of sentence in train set : \", len(train_files))\n",
    "    print(\"Number of sentence in test set : \", len(test_files))\n",
    "    \n",
    "    with open(os.path.join(out_dir, 'tsync2_train.json'), 'w') as tr:\n",
    "        for train_file in train_files:\n",
    "            if train_file!='' and train_file is not None:\n",
    "                tr.write(train_file)\n",
    "    \n",
    "    with open(os.path.join(out_dir, 'tsync2_test.json'), 'w') as tt:\n",
    "        for test_file in test_files:\n",
    "            if test_file!='' and test_file is not None:\n",
    "                tt.write(test_file)\n",
    "\n",
    "create_menifest(\"TSync2\", \"TSync2_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "from nemo.collections.common.callbacks import LogEpochTimeCallback\n",
    "from nemo.collections.tts.models import Tacotron2Model, WaveGlowModel\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "\n",
    "from nemo.utils.exp_manager import exp_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('tacotron2_th.yaml')\n",
    "\n",
    "trainer = pl.Trainer(**cfg.trainer)\n",
    "\n",
    "exp_manager(trainer, cfg.get(\"exp_manager\", None))\n",
    "\n",
    "model = Tacotron2Model(cfg=cfg.model, trainer=trainer)\n",
    "\n",
    "# Let's add a few more callbacks\n",
    "lr_logger = pl.callbacks.LearningRateMonitor()\n",
    "epoch_time_logger = LogEpochTimeCallback()\n",
    "trainer.callbacks.extend([lr_logger, epoch_time_logger])\n",
    "# Call lightning trainer's fit() to train the model\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Tacotron2Model.restore_from(\"Tacotron2.nemo\")\n",
    "model.to('cuda:0')\n",
    "\n",
    "# Load vocoder\n",
    "vocoder = WaveGlowModel.from_pretrained(model_name=\"tts_waveglow_268m\")\n",
    "vocoder.to('cuda:0')\n",
    "\n",
    "token_input = model.parse('ภาษาไทย ง่าย นิด เดียว') # map character to index\n",
    "spec_gen = model.generate_spectrogram(tokens=token_input.to('cuda:0')) # generate spectrogram\n",
    "audio = vocoder.convert_spectrogram_to_audio(spec=spec_gen) # convert spectrogram to waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "ipd.Audio(audio.cpu().numpy(), rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
